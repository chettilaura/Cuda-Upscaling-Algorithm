\section{Proposed Method}

In this section we will give to the lecturer a detailed description of the proposed algorithm: 
some implemented procedures will be explained through pseudocode. 
The algorithm works in successive stages as described in the following:

\begin{itemize}
    \item Kernel loading
    \item Image reading
    \item Image cut out
    \item Image enlargement and filling
    \item Image enhancement
\end{itemize}

    \subsection{Kernel Loading}
    The algorithm can choose between custom kernels given as input from files, or gaussian ones, which are generated on the fly,
    taking as input the length of the kernel and the $\Sigma$ value. Once generation is done, the kernel is loaded into 
    the constant memory of the GPU.\\ % Add motivations and performance improvements to why this is done

    \subsection{Image Cut-Out}
    The aim of this step is to select the part of the original image that has to be trimmed: 
    the dimension of the cut area is passed through command line and the script subsequently calculates the dimension of image in output.  \\ 
    The measure of the side of the final image is computed choosing the largest multiple, 
    smaller than the smallest dimension between width and height of the original image. These checks are performed in order to avoid the creation of a final 
    image with a dimension that is not a multiple of the side of the cut area.\\
    The function carries out the logic explained down below:

    \begin{equation}
        img_out[tid] = img[starting\_byte + row\_offset + column\_offset]
    \end{equation}
    
    where $tid$ is the thread id, $img\_out$ is the final image, $img$ is the original image, $starting\_byte$ is the starting byte of the cut area, 
    $row\_offset$ is the offset of the row of the pixel to be copied and $column\_offset$ is the offset of the column of the pixel to be copied.
    The implementation is basic, it is a simple copy of the pixels from the original image to the final one, done in parallel using CUDA threads.\\

    \subsection{Image Enlargement and Filling}
    This step is the one that enlarges the image and fills the holes that are created by the zooming process.
    The process begins by creating as many threads as are the bytes in the final image, and each one of them computes 
    the value of the pixel to be copied from the original image, so that all holes are filled.\\
    The holes are filled with the help of the pixel replication algorithm. 
    It replicates the neighboring pixels in order to increase them to enlarge the image: it creates new pixels from the already given ones, 
    and it is the most basic technique of implementing the zooming technique, giving as output an image blurred and with lots of artifacts.\\ 
    In the first version of the algorithm, while filling the canvas with the enlarged image, a black border is left around the image,
    which will be used to perform the convolution with the filter, which needs a larger image than the one that is actually returned as output, whichever
    the position from which to start the zooming from.
    The final version of the algorithm, instead, performs the enlargement, and if the cutout is not at the border, the program will use neighboring pixels
    to create a slightly bigger image for the convolution. If the cutout is at the border, instead, the back border will be used just for the border part, 
    leaving a small, unnoticeable shade at the last pixels of the image. This final version allows to have an image which is even more faithful to the original one.\\

    % \begin{equation}
    %     \begin{split}
    %         img\_out &[start\_edge\_coord + r\_dim\_lrgst\_img + c\_dim\_lrgst\_img + col\_offset ] =\\
    %             &= img[r\_offset\_smlr\_img + c\_offset\_smlr\_img + col\_offset\_img]
    %     \end{split}
    % \end{equation}



    \subsection{Image Enhancement}
    % versione1 GPU -> basicConvGpu (usata come fallback)
    % versione2 GPU -> ConvGpu (tiling)
    % {versione3 GPU -> ConvGpu (tiling + conflitti banchi shared)}

    % classica convoluzione da memoria globale prende dati necessari, la maschera sta nella constant memory 

    % versione tiling: difficoltà gestione dei 3 colori -> abbiamo gestito i colori singolarmente per blocco: i threads di ogni blocco lavorano su uno stesso colore.
    % L’immagine è stata frammentata per lavorare su più parti in parallelo, ogni frammento di immagine espresso in pixel (tile) è elaborato a gruppi di tre blocks: uno per ogni colore  
    % la chiamata kernel specifica la dimensione della shared memory: una per ogni blocco. 
    % nel kernel TUTTI i threads del blocco partecipano a riempire la shared memory e poi solo alcuni di essi partecipano a calcolare la convoluzione con la maschera per quel blocco.
    % Il numero dei threads per blocco è pari al numero dei bytes della shared memory (bigTileDim*bigTileDim)
    % il riempimento della shared memory è fatto byte per byte e non pixel x pixel quindi gli offset di riempimento devono tenere conto di questo 
    % la convoluzione è fatta tra il singolo canale-colore del pixel e la maschera 
    % come indici dei threads usiamo threadId.x & threadId.y perchè così ci aiutano ad avere degli indici sensati per  spostarci logicamente nella matrice sia per il riempimento della shared memory che per la convoluzione (ma in realtà avremmo potuto usare una sola dimensione per gli indici dei threads)
    % con il termine ti tiling ci riferiamo all’utilizzo della shared memory per assegnazione ai blocchi del materiale su cui lavorare. 


